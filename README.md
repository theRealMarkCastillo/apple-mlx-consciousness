# ğŸ§  Apple MLX Consciousness Research

[![MLX](https://img.shields.io/badge/MLX-0.30.0-blue)](https://github.com/ml-explore/mlx)
[![Python](https://img.shields.io/badge/Python-3.13+-green)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

**Pushing the boundaries of cognitive simulation using Apple Silicon's unified memory architecture.**

This research project explores how **Apple Silicon (M-series chips)** enables breakthrough implementations of consciousness theories at scale. By leveraging **64GB unified memory** with zero-copy data sharing, we simulate multi-agent cognitive systems impossible on traditional GPU architectures.

---

## ğŸ¯ Project Vision

**Hypothesis:** Apple Silicon's unified memory architecture enables novel cognitive simulations that demonstrate emergent collective consciousness in multi-agent systems.

**Current Focus:** Progressing from single-agent cognition â†’ multi-agent swarms â†’ heterogeneous (GPU + NPU) dual-process learning â†’ multimodal perception (vision + text) with persistent state.

**Target Impact:** Publishable research at the intersection of cognitive science, AI/ML, and systems architecture.

---

## ğŸ—ï¸ Architecture Overview

Core agents:

For concise, command-only instructions see **`QUICKSTART.md`**.
Below is the extended context version (keep this high-level; details live in Quickstart file).
- `BicameralAgent`: Original dual-process + global workspace implementation.
### Installation (summary)
Clone, enter, install deps:
```bash
git clone https://github.com/theRealMarkCastillo/apple-mlx-consciousness.git
cd apple-mlx-consciousness
pip install -r requirements.txt
```
- **Apple Silicon Advantage:** Zero-copy access from CPU, GPU, and Neural Engine
### Run Examples (abbreviated)
Further commands (vision, benchmarking, swarm, persistence) consolidated in `QUICKSTART.md`.
â”œâ”€â”€ sensory_cortex.py               # VisualCortex + MultiModalFuser (vision/text grounding)
â”œâ”€â”€ biological_nlp.py               # SDR encoder + associative memory
â”œâ”€â”€ conscious_chatbot.py            # Multimodal conscious interface (stateful)
â”œâ”€â”€ visual_simulation.py            # Real-time System1 vs System2 demonstration
â”œâ”€â”€ benchmark_performance.py        # Latency / throughput / memory compression
â”œâ”€â”€ train_from_data.py              # Offline behavioral cloning + brain persistence
â”œâ”€â”€ train_vision.py                 # Vision-text alignment (synthetic shapes & colors)
â”œâ”€â”€ generate_training_data.py       # Synthetic experiences + conversation data
â”œâ”€â”€ foraging_environment.py         # Resource collection task for swarms
â”‚
â”œâ”€â”€ 01_Global_Workspace_Demo.ipynb
â”œâ”€â”€ 02_Learning_and_Dreaming.ipynb
â”œâ”€â”€ 03_Conscious_Chatbot_Internals.ipynb
â”œâ”€â”€ 04_Multi_Agent_Swarm_Demo.ipynb
â”œâ”€â”€ 05_Phase_Transitions.ipynb
â”œâ”€â”€ 06_Heterogeneous_Compute.ipynb
â”œâ”€â”€ 08_Multimodal_Consciousness.ipynb
â”‚
â”œâ”€â”€ ROADMAP.md  â”‚ ALIGNMENT_REVIEW.md â”‚ requirements.txt â”‚ .gitignore
â””â”€â”€ README.md
```

### Key Files

| File | Description | Status |
|------|-------------|--------|
| **`cognitive_architecture.py`** | Complete implementation (417 lines) with all cognitive modules | âœ… Phase 1 Complete |
| **`swarm_architecture.py`** | Multi-agent system (407 lines) - collective consciousness at scale | âœ… Phase 2 Complete |
| **`heterogeneous_architecture.py`** | GPU-NPU heterogeneous compute - 3.2Ã— memory compression | âœ… Phase 4 Complete |
| **`sensory_cortex.py`** | VisualCortex + MultiModalFuser (CLIP-like alignment) | âœ… Phase 5 Extension |
| **`train_vision.py`** | Synthetic shape/color grounding (vision â†” text) | âœ… Added |
| **`visual_simulation.py`** | Live System1 vs System2 cognitive cycle visualization | âœ… Added |
| **`benchmark_performance.py`** | Latency & throughput comparison (quantized vs full) | âœ… Added |
| **`train_from_data.py`** | Offline sleep consolidation + brain persistence | âœ… Updated |
| **`consciousness_metrics.py`** | Î¦, metacognition, coherence metrics (337 lines) | âœ… Phase 3 Complete |
| **`phase_transition_experiment.py`** | Parameter sweep infrastructure (427 lines) | âœ… Phase 3 Complete |
| **`01_Global_Workspace_Demo.ipynb`** | â­ **START HERE** - Educational notebook with theory and visualizations | âœ… Enhanced with theory |
| **`02_Learning_and_Dreaming.ipynb`** | Demonstrates sleep consolidation benefits | âœ… Ready to run |
| **`03_Conscious_Chatbot_Internals.ipynb`** | Real-time visualization of chatbot's thoughts | âœ… Updated to 128D |
| **`04_Multi_Agent_Swarm_Demo.ipynb`** | Collective consciousness experiments with 10-100 agents | âœ… Phase 2 Complete |
| **`05_Phase_Transitions.ipynb`** | Consciousness emergence analysis with 3D visualizations | âœ… Phase 3 Complete |
| **`06_Heterogeneous_Compute.ipynb`** | Quantization, scaling, and hippocampus-cortex learning | âœ… Phase 4 Complete |
| **`benchmark_energy.py`** | Energy consumption stress test (NPU vs GPU) | âœ… Phase 4 Complete |
| **`ROADMAP.md`** | Research timeline: single-agent â†’ multi-agent swarm â†’ phase transitions | ğŸ“‹ 16+ research directions |
| **`ALIGNMENT_REVIEW.md`** | Phase 1â†’2 transition validation and checklist | âœ… 98% aligned |
| **`simulation.py`** | Terminal demo showing flow states, recall events, and dreaming | âœ… Working |

---

## ğŸš€ Quick Start

### Prerequisites

- **macOS** with Apple Silicon (M1/M2/M3/M4)
- **Python 3.13+**
- **64GB RAM recommended** (for multi-agent experiments)
  - **Tested on:** Mac Mini M4 Pro (Model: Mac16,11)
  - **CPU:** 14 cores (10 performance + 4 efficiency)
  - **GPU:** 20 cores with Metal 4
  - **Memory:** 64GB LPDDR5 unified

### Installation

```bash
git clone https://github.com/theRealMarkCastillo/apple-mlx-consciousness.git
cd apple-mlx-consciousness

# Install dependencies
pip install -r requirements.txt
```

### Run Examples

**1. Interactive Notebooks (Recommended)**
```bash
# Open in VS Code or Jupyter
code 01_Global_Workspace_Demo.ipynb
```

**2. Terminal Simulation**
```bash
python simulation.py
```
*Watch for `ğŸ”´ RECALL` (memory retrieval) and `ğŸŸ¢ Flow` (automatic processing)*

**3. Conscious Chatbot (Stateful; loads vision + brain if present)**
```bash
python conscious_chatbot.py
```
*Chat with an agent that shows its internal confidence and thought process*

**4. Vision Grounding (Synthetic shapes/colors)**
```bash
python train_vision.py
```
Produces: `visual_cortex.npz`, `multimodal_fuser.npz`

**5. Offline Behavioral Cloning + Persistence**
```bash
python generate_training_data.py   # (once) create synthetic_experiences.json
python train_from_data.py          # trains System1 â†’ saves agent_brain.npz
```

**6. Performance Benchmark (NPU vs GPU)**
```bash
python benchmark_performance.py
```

**7. Visual Cognitive Simulation**
```bash
python visual_simulation.py
```
Observe: Blue = System1 (fast), Orange = System2 (deliberate)

**8. Swarm / Foraging**
```bash
# Wake-Sleep Active Learning
python heterogeneous_training.py

# Adversarial Co-Evolution
python adversarial_coevolution.py

# Sparse Memory Scaling
python sparse_memory.py
```

---

## ğŸ“Š Current Results (Latest Additions)

### Heterogeneous Performance (Quantized vs Full Precision)
| Metric | Quantized (NPU+GPU) | Full Precision (GPU only) |
|--------|---------------------|---------------------------|
| Throughput (steps/sec) | ~949 | ~855 |
| P50 Latency (ms) | 0.93 | 0.99 |
| P99 Latency (ms) | 1.83 | 4.40 |
| System1 Size | 22 KB | 70 KB |
| Compression | 3.2Ã— | â€” |

Interpretation: NPU path slightly improves worst-case latency and reduces model memory, enabling larger swarms and always-on modes.

### Architecture Specifications

- **State Dimensions:** 128D (optimized for M4 Pro cache efficiency)
- **Action Space:** 3-10 actions (configurable per application)
- **System 1 Hidden Layers:** 128 neurons
- **System 2 Hidden Layers:** 64 neurons
- **Memory Capacity:** Tested with 10K+ episodes

### Latest Simulation Results (`simulation.py`)

**20-step simulation with random sensory input:**
- **Memory Stored:** 19 episodic experiences
- **System 2 Interventions:** 10/20 steps (50% recall rate)
- **Confidence Range:** 0.36-0.59 (moderate, expected for random input)
- **Entropy Range:** 0.00-1.61 (decreasing over time as patterns emerge)
- **World Model MSE:** 0.4040 after sleep consolidation

### Notebook Demonstration (`01_Global_Workspace_Demo.ipynb`)

**50-step extended simulation:**
- **Total Memories:** ~50 episodic experiences
- **Cognitive Flow:** Agent learns to stabilize entropy over time
- **Dreaming Effect:** World Model prediction error reduces significantly
- **Visualizations:** 5 interactive plots showing consciousness dynamics

### Available Visualizations

1. **Global Workspace Heatmap** - 128D "stream of consciousness" (8Ã—16 grid)
2. **Entropy vs. Confidence** - Meta-cognitive monitoring over time
3. **Goal Vector Evolution** - Top-down attention patterns (System 2)
4. **Action Probability Stream** - Decision-making dynamics
5. **Phase Space Scatter** - Cognitive state transitions (flow/recall/imagination)
6. **Chatbot Thought Vectors** - Real-time visualization of internal processing

---

## ğŸ”¬ Research Roadmap

See **[ROADMAP.md](ROADMAP.md)** for detailed timeline. Summary:

### âœ… Phase 1: Foundation (COMPLETED)
- Single-agent architecture validated (128D state space)
- Educational materials with comprehensive theory explanations
- Baseline performance metrics established
- **All 3 notebooks functional and tested**
- **Code quality:** 417 lines, well-documented, type-hintable

### âœ… Phase 2: Multi-Agent Swarm (COMPLETED)
- âœ… `ConsciousSwarm` class with shared 512D workspace (407 lines)
- âœ… 100+ agent system validated with unified memory
- âœ… Agent-to-agent communication (broadcast/unicast/multicast)
- âœ… Collective foraging environment with emergent behavior
- âœ… Scaling benchmarks: 100 agents = 0.05MB, 95% consensus
- âœ… Projected capacity: **120M agents** with 64GB unified memory
- **Memory footprint:** 0.5KB per agent (ultra-efficient)

**Phase 2 Results:**
- **Scaling:** Tested 10â†’50â†’100 agents (18.5 agent-steps/sec)
- **Consensus:** 95% agreement in 100-agent swarm
- **Foraging:** 2 resources collected, 9540 shared memories
- **Learning:** World Model MSE improved 0.52â†’0.31

### âœ… Phase 3: Consciousness Phase Transitions (COMPLETED)
- âœ… Implemented Integrated Information Theory (Î¦) metrics
- âœ… Metacognitive accuracy and world model coherence tracking
- âœ… Parameter sweep infrastructure (memory, state dimensions)
- âœ… 8 configurations tested in 1.3 seconds
- âœ… Key finding: **No phase transitions detected** - consciousness is robust!

**Phase 3 Results:**
- **All configurations conscious** (index: 0.53-0.64)
- **Î¦ range:** 0.40-0.58 (integrated information)
- **Metacognition:** 1.0 (perfect prediction accuracy)
- **Implication:** Architecture is stable, not fragile
- **Next:** Test extreme parameters to find boundaries

### ğŸš€ Phase 4: Heterogeneous Compute (COMPLETED)
- âœ… GPU-NPU heterogeneous feedback loop
- âœ… INT8 quantization: **3.2x memory compression**
- âœ… Capacity increase: 949â†’3,039 agents (64GB)
- âœ… Hippocampus-cortex learning split (online/offline)
- âœ… **Real Backpropagation:** Sleep consolidation now trains System 1 weights
- âœ… **Energy Benchmarking:** `benchmark_energy.py` for NPU vs GPU power analysis
- âœ… Zero accuracy loss (MSE ~2e-5)

**Phase 4 Results:**
- **Single-agent:** 10% overhead (dequantization cost)
- **Real advantage:** Memory capacity, not speed
- **Scaling tested:** 10â†’200 agents successfully
- **Learning:** 4 sleep cycles, 200 experiences consolidated with loss reduction
- **Biological plausibility:** Dual-process + hippocampus analogy
- **Next:** 500+ agent tests, Phase 5 hardware-aware innovations

### ğŸ”® Phase 5: Hardware-Aware / Multimodal Innovations (COMPLETED)
- âœ… **Wake-Sleep Active Learning:** `heterogeneous_training.py`
- âœ… **Adversarial Co-Evolution:** `adversarial_coevolution.py`
- âœ… **Sparse Memory Scaling:** `sparse_memory.py` (20x capacity)

**Phase 5 Results:**
- **Active Learning:** Rapid convergence on hard examples
- **Adversarial Robustness:** Disagreement minimized (0.06 â†’ 0.003)
- **Memory Capacity:** 168M memories on 32GB system (Sparse)
- **Multimodal Alignment:** Vision â†’ text cosine similarity ~0.73 (synthetic labeling)

---

## ğŸ’¡ Why Apple Silicon?

### Unified Memory Advantage

Traditional GPU systems suffer from:
- âŒ Limited VRAM (16-24GB typical)
- âŒ PCIe transfer bottleneck (CPU â†” GPU copying)
- âŒ Separate memory pools for multi-agent systems

**Apple Silicon M4 Pro (Mac Mini):**
- âœ… **14-core CPU** (10 performance + 4 efficiency cores)
- âœ… **20-core GPU** with Metal 4 support
- âœ… **16-core Neural Engine** for ML acceleration
- âœ… **64GB unified LPDDR5 memory** shared across all processors
- âœ… **Zero-copy architecture** - no data transfer overhead
- âœ… **273 GB/s bandwidth** - instant access to 10M+ memories
- âœ… **Energy efficient** - ~100W vs. 450W for NVIDIA 4090

### Concrete Benefits for Cognitive Simulation

| Feature | Traditional GPU | Apple M4 Pro (64GB) |
|---------|----------------|---------------------|
| Agent capacity | 10â€“20 | 100+ (tested) |
| Shared memory | Duplicated / copied | Single zero-copy pool |
| State dimensions | 32â€“64D | 128D (fast cache reuse) |
| Memory retrieval | ~1M practical | 10M+ feasible |
| Transfer overhead | PCIe bottlenecks | None (unified) |
| Multi-model execution | Sequential | Concurrent CPU/GPU/NPU |
| Power consumption | 300â€“450W | ~40â€“60W |

---

## ğŸ“ Educational Resources

### Notebooks Include Theory Explanations

Each notebook contains:
- ğŸ“š **Theoretical background** - Original papers and key concepts
- ğŸ—ï¸ **Architectural decisions** - Why we implemented it this way
- ğŸ“Š **Result interpretation** - What the visualizations mean
- ğŸ”§ **Suggested experiments** - How to extend the research

### Key References

- **Baars, B. J. (1988).** *A Cognitive Theory of Consciousness.* Cambridge University Press.
- **Kahneman, D. (2011).** *Thinking, Fast and Slow.* Farrar, Straus and Giroux.
- **Tononi, G. (2004).** "An information integration theory of consciousness." *BMC Neuroscience*.
- **Dehaene, S. et al. (2017).** "What is consciousness, and could machines have it?" *Science*.

---

## ğŸ¤ Contributing

This is an active research project. Contributions welcome in:

- **Code:** Performance optimizations, new cognitive modules
- **Science:** Novel experiments, metric proposals, theory integration
- **Documentation:** Tutorial notebooks, architecture explanations
- **Benchmarking:** Comparisons with other frameworks/hardware

**To contribute:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/<short-topic>`) 
3. Keep patches focused (architecture, metrics, performance)
4. Open a PR with: context, rationale, benchmark (if perf-related)

Please avoid committing large generated artifacts (`*.npz`, synthetic JSON) â€” already excluded via `.gitignore`.

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Apple MLX Team** - For the incredible unified memory framework
- **Bernard Baars** - Global Workspace Theory foundation
- **Daniel Kahneman** - Dual-process theory insights
- **Jeff Hawkins** - HTM inspiration for future work

---

## ğŸ“¬ Contact & Updates

- **GitHub Issues:** Use repository issue tracker (bug reports, feature proposals)
- **Discussions:** Open for theoretical debate & experiment sharing
- **Updates:** Follow the repoâ€™s releases & commit log

> If publishing derived research, please cite original theory sources and link back here.

---

## ğŸŒŸ Star History

If you find this research useful, please â­ star the repository to help others discover it!

---

**Built with â¤ï¸ on Apple Silicon | Exploring the computational basis of consciousness**
